"data/SF3.scores",
"data/SF4.scores",
"data/SF5.scores"
)
x = read.table(RESULTS_FILES[1], header = TRUE)
valid_molnames <- as.vector(x[1])
for (i in 2:length(RESULTS_FILES)) {
y = read.table(RESULTS_FILES[i], header = TRUE)
print(head(y[1]))
valid_molnames <- intersect(valid_molnames, as.vector(y[1]))
}
valid_molnames
x = read.table(RESULTS_FILES[1], header = TRUE)
valid_molnames <- x[1]
i=2
y = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- intersect(valid_molnames, y[1])
valid_molnames
x = read.table(RESULTS_FILES[1], header = TRUE)
valid_molnames <- x[1]
#for (i in 2:length(RESULTS_FILES)) {
i=2
y = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- intersect(valid_molnames, y[1])
#}
i=3
y = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- intersect(valid_molnames, y[1])
i=4
y = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- intersect(valid_molnames, y[1])
i=5
y = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- intersect(valid_molnames, y[1])
valid_molnames
x = read.table(RESULTS_FILES[1], header = TRUE)
valid_molnames <- x[1]
#for (i in 2:length(RESULTS_FILES)) {
i=2
y = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- intersect(valid_molnames, y[1])
valid_molnames
x = read.table(RESULTS_FILES[1], header = TRUE)
valid_molnames <- x[1]
#for (i in 2:length(RESULTS_FILES)) {
i=2
y = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- intersect(valid_molnames, y[1])
valid_molnames
y
valid_molnames <- c()
for (i in 1:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- c(valid_molnames, x[1])
}
valid_molnames
length(valid_molnames)
valid_molnames <- c()
for (i in 1:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- c(valid_molnames, as.vector(x[1]))
}
length(valid_molnames)
valid_molnames[1]
valid_molnames[2]
c(c(), c(1,2,3))
v <- c(c(), c(1,2,3))
v
valid_molnames <- vector()
for (i in 1:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- c(valid_molnames, as.vector(x[1]))
}
valid_molnames[2]
valid_molnames <- vector()
for (i in 1:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
valid_molnames <- c(valid_molnames, as.vector(x[1]))
}
valid_molnames
length(valid_molnames)
valid_molnames <- vector()
for (i in 1:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
colnames(x)[1] = "molname"
colnames(x)[2] = "score"
valid_molnames <- c(valid_molnames, as.vector(x$molname))
}
valid_molnames
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- x$molname
for (i in 2:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- intersect(valid_molnames, x$molname)
}
valid_molnames
length(valid_molnames)
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- x$molname
vvalid_molnames
length(valid_molnames)
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- x$molname
length(valid_molnames)
x = read.table(RESULTS_FILES[1], header = TRUE)
RESULTS_FILES = c("data/SF1.scores",
"data/SF2.scores",
"data/SF3.scores",
"data/SF4.scores",
"data/SF5.scores"
)
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- x$molname
length(valid_molnames)
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- unique(sort(x$molname))
length(valid_molnames)
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- unique(sort(x$molname)) ; # unique molnames
for (i in 2:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- intersect(valid_molnames, x$molname)
}
length(valid_molnames)
RESULTS_FILES = c("data/SF1.scores",
"data/SF2.scores",
"data/SF3.scores",
"data/SF4.scores",
"data/SF5.scores"
)
valid_molnames <- common_molnames(RESULTS_FILES)  ; # molnames with scores by all scoring functions
# You could also have several functions in a single R file and still document them separately. Simply put an identifier
# starting with ## ---- before each function definition and then create empty chunks referring to each one of the identifiers.
library("ROCR")
library("hash")
## ---- find the molnames that are common in all score files in order to compare the scoring functions correctly
common_molnames <- function(RESULTS_FILES) {
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- unique(sort(x$molname)) ; # unique molnames
for (i in 2:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- intersect(valid_molnames, x$molname)
}
}
## ---- read_scores
read_scores <- function(RESULTS_FILE, ACTIVITIE_FILE, valid_molnames) {
"
The valid_molnames list ensures that only the molnames that were scored by all scoring functions will
be considered.
"
x = read.table(RESULTS_FILE, header = TRUE)
colnames(x)[2] = "score"
# ignore the other columns
score_dict = hash()
for (i in seq(1, nrow(x))) { score_dict[x[i,1]] <- x[i,2] }
a = read.table(ACTIVITIES_FILE)
colnames(a)[1] = "molname"
colnames(a)[2] = "label"
label_dict = hash()
for (i in seq(1, nrow(a))) { label_dict[a[i,1]] <- a[i,2] }
scores <- rep(0, length(valid_molnames))
labels <- rep("", length(valid_molnames))  ; # initialize labels to a list of size(scores) but without contents
i = 1
for (molname in valid_molnames) {
scores[i] <- score_dict[[molname]]
labels[i] <- label_dict[[molname]]
i <- i+1
}
pred = prediction(-1*scores, labels)  ;# IMPORTANT: -1* because the function prediction() assumes that the highest the score the better
return(pred)
}
RESULTS_FILES = c("data/SF1.scores",
"data/SF2.scores",
"data/SF3.scores",
"data/SF4.scores",
"data/SF5.scores"
)
valid_molnames <- common_molnames(RESULTS_FILES)  ; # molnames with scores by all scoring functions
ACTIVITIES_FILE = "data/activities"
NAMES <- c("Scoring Function 1", "Sscoring Function 2", "Scoring Function 3", "Scoring Function 4",
"Scoring Function 5")
par(cex.main=2.0, cex.lab=1.5) ; # <== CHANGE ME
library("ROCR")
library("hash")
COLORS <- rainbow(3*length(RESULTS_FILES))
COLORS <- COLORS[seq(3, length(COLORS), 3)]
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
perf = performance(pred, 'tpr', 'fpr')
if (i==1) { plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves") }
else { plot(perf, add = TRUE, colorize = FALSE, lwd=3, col=COLORS[i]) }
# plot(perf2, add = TRUE, colorize = TRUE, lwd=3)
# plot(perf3, add = TRUE, colorize = TRUE, lwd=3)
}
# You could also have several functions in a single R file and still document them separately. Simply put an identifier
# starting with ## ---- before each function definition and then create empty chunks referring to each one of the identifiers.
library("ROCR")
library("hash")
## ---- find the molnames that are common in all score files in order to compare the scoring functions correctly
common_molnames <- function(RESULTS_FILES) {
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- unique(sort(x$molname)) ; # unique molnames
for (i in 2:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- intersect(valid_molnames, x$molname)
}
}
## ---- read_scores
read_scores <- function(RESULTS_FILE, ACTIVITIES_FILE, valid_molnames) {
"
The valid_molnames list ensures that only the molnames that were scored by all scoring functions will
be considered.
"
x = read.table(RESULTS_FILE, header = TRUE)
colnames(x)[2] = "score"
# ignore the other columns
score_dict = hash()
for (i in seq(1, nrow(x))) { score_dict[x[i,1]] <- x[i,2] }
a = read.table(ACTIVITIES_FILE)
colnames(a)[1] = "molname"
colnames(a)[2] = "label"
label_dict = hash()
for (i in seq(1, nrow(a))) { label_dict[a[i,1]] <- a[i,2] }
scores <- rep(0, length(valid_molnames))
labels <- rep("", length(valid_molnames))  ; # initialize labels to a list of size(scores) but without contents
i = 1
for (molname in valid_molnames) {
scores[i] <- score_dict[[molname]]
labels[i] <- label_dict[[molname]]
i <- i+1
}
pred = prediction(-1*scores, labels)  ;# IMPORTANT: -1* because the function prediction() assumes that the highest the score the better
return(pred)
}
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
perf = performance(pred, 'tpr', 'fpr')
if (i==1) { plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves") }
else { plot(perf, add = TRUE, colorize = FALSE, lwd=3, col=COLORS[i]) }
# plot(perf2, add = TRUE, colorize = TRUE, lwd=3)
# plot(perf3, add = TRUE, colorize = TRUE, lwd=3)
}
i
RESULTS_FILES[i]
ACTIVITIES_FILE
getwd(\)
getwd()
valid_molnames
# You could also have several functions in a single R file and still document them separately. Simply put an identifier
# starting with ## ---- before each function definition and then create empty chunks referring to each one of the identifiers.
library("ROCR")
library("hash")
## ---- find the molnames that are common in all score files in order to compare the scoring functions correctly
common_molnames <- function(RESULTS_FILES) {
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- unique(sort(x$molname)) ; # unique molnames
for (i in 2:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- intersect(valid_molnames, x$molname)
}
return(valid_molnames)
}
## ---- read_scores
read_scores <- function(RESULTS_FILE, ACTIVITIES_FILE, valid_molnames) {
"
The valid_molnames list ensures that only the molnames that were scored by all scoring functions will
be considered.
"
x = read.table(RESULTS_FILE, header = TRUE)
colnames(x)[2] = "score"
# ignore the other columns
score_dict = hash()
for (i in seq(1, nrow(x))) { score_dict[x[i,1]] <- x[i,2] }
a = read.table(ACTIVITIES_FILE)
colnames(a)[1] = "molname"
colnames(a)[2] = "label"
label_dict = hash()
for (i in seq(1, nrow(a))) { label_dict[a[i,1]] <- a[i,2] }
scores <- rep(0, length(valid_molnames))
labels <- rep("", length(valid_molnames))  ; # initialize labels to a list of size(scores) but without contents
i = 1
for (molname in valid_molnames) {
scores[i] <- score_dict[[molname]]
labels[i] <- label_dict[[molname]]
i <- i+1
}
pred = prediction(-1*scores, labels)  ;# IMPORTANT: -1* because the function prediction() assumes that the highest the score the better
return(pred)
}
valid_molnames <- common_molnames(RESULTS_FILES)  ; # molnames with scores by all scoring functions
valid_molnames
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
valid_molnames
ACTIVITIES_FILE
RESULTS_FILE= RESULTS_FILES[i]
ACTIVITIES_FILE
valid_molnames
x = read.table(RESULTS_FILE, header = TRUE)
colnames(x)[2] = "score"
# ignore the other columns
score_dict = hash()
for (i in seq(1, nrow(x))) { score_dict[x[i,1]] <- x[i,2] }
score_dict
a = read.table(ACTIVITIES_FILE)
colnames(a)[1] = "molname"
colnames(a)[2] = "label"
label_dict = hash()
for (i in seq(1, nrow(a))) { label_dict[a[i,1]] <- a[i,2] }
scores <- rep(0, length(valid_molnames))
labels <- rep("", length(valid_molnames))  ; # initialize labels to a list of size(scores) but without contents
i = 1
scores
labels
for (molname in valid_molnames) {
scores[i] <- score_dict[[molname]]
labels[i] <- label_dict[[molname]]
i <- i+1
}
scores
labels
# You could also have several functions in a single R file and still document them separately. Simply put an identifier
# starting with ## ---- before each function definition and then create empty chunks referring to each one of the identifiers.
library("ROCR")
library("hash")
## ---- find the molnames that are common in all score files in order to compare the scoring functions correctly
common_molnames <- function(RESULTS_FILES) {
x = read.table(RESULTS_FILES[1], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- unique(sort(x$molname)) ; # unique molnames
for (i in 2:length(RESULTS_FILES)) {
x = read.table(RESULTS_FILES[i], header = TRUE)
colnames(x)[1] = "molname"
valid_molnames <- intersect(valid_molnames, x$molname)
}
return(valid_molnames)
}
## ---- read_scores
read_scores <- function(RESULTS_FILE, ACTIVITIES_FILE, valid_molnames) {
"
The valid_molnames list ensures that only the molnames that were scored by all scoring functions will
be considered.
"
x = read.table(RESULTS_FILE, header = TRUE)
colnames(x)[2] = "score"
# ignore the other columns
score_dict = hash()
for (i in seq(1, nrow(x))) { score_dict[x[i,1]] <- x[i,2] }
a = read.table(ACTIVITIES_FILE)
colnames(a)[1] = "molname"
colnames(a)[2] = "label"
label_dict = hash()
for (i in seq(1, nrow(a))) { label_dict[a[i,1]] <- a[i,2] }
scores <- rep(0, length(valid_molnames))
labels <- rep("", length(valid_molnames))  ; # initialize labels to a list of size(scores) but without contents
i = 1
for (molname in valid_molnames) {
scores[i] <- score_dict[[molname]]
labels[i] <- label_dict[[molname]]
i <- i+1
}
pred = prediction(-1*scores, labels)  ;# IMPORTANT: -1* because the function prediction() assumes that the highest the score the better
return(pred)
}
RESULTS_FILES = c("data/SF1.scores",
"data/SF2.scores",
"data/SF3.scores",
"data/SF4.scores",
"data/SF5.scores"
)
valid_molnames <- common_molnames(RESULTS_FILES)  ; # molnames with scores by all scoring functions
length(valid_molnames)
ACTIVITIES_FILE = "data/activities"
NAMES <- c("Scoring Function 1", "Sscoring Function 2", "Scoring Function 3", "Scoring Function 4",
"Scoring Function 5")
par(cex.main=2.0, cex.lab=1.5) ; # <== CHANGE ME
library("ROCR")
library("hash")
COLORS <- rainbow(3*length(RESULTS_FILES))
COLORS <- COLORS[seq(3, length(COLORS), 3)]
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
perf = performance(pred, 'tpr', 'fpr')
if (i==1) { plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves") }
else { plot(perf, add = TRUE, colorize = FALSE, lwd=3, col=COLORS[i]) }
# plot(perf2, add = TRUE, colorize = TRUE, lwd=3)
# plot(perf3, add = TRUE, colorize = TRUE, lwd=3)
}
AUCs = rep(0, length(RESULTS_FILES))
LNAMES = rep(0, length(RESULTS_FILES))
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILES[i])
auc = performance(pred, measure='auc')
AUCs[i] = sprintf("%.3f", auc@y.values)
LNAMES[i] = paste(NAMES[i], "(", AUCs[i],")")
# print(paste(NAMES[i], "AUC-ROC=", auc@y.values))
}
AUCs = rep(0, length(RESULTS_FILES))
LNAMES = rep(0, length(RESULTS_FILES))
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE)
auc = performance(pred, measure='auc')
AUCs[i] = sprintf("%.3f", auc@y.values)
LNAMES[i] = paste(NAMES[i], "(", AUCs[i],")")
# print(paste(NAMES[i], "AUC-ROC=", auc@y.values))
}
AUCs = rep(0, length(RESULTS_FILES))
LNAMES = rep(0, length(RESULTS_FILES))
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
auc = performance(pred, measure='auc')
AUCs[i] = sprintf("%.3f", auc@y.values)
LNAMES[i] = paste(NAMES[i], "(", AUCs[i],")")
# print(paste(NAMES[i], "AUC-ROC=", auc@y.values))
}
abline(a=0, b=1, lty=2, lwd=3, col="black")
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
perf = performance(pred, 'tpr', 'fpr')
if (i==1) { plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves") }
else { plot(perf, add = TRUE, colorize = FALSE, lwd=3, col=COLORS[i]) }
# plot(perf2, add = TRUE, colorize = TRUE, lwd=3)
# plot(perf3, add = TRUE, colorize = TRUE, lwd=3)
}
AUCs = rep(0, length(RESULTS_FILES))
LNAMES = rep(0, length(RESULTS_FILES))
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
auc = performance(pred, measure='auc')
AUCs[i] = sprintf("%.3f", auc@y.values)
LNAMES[i] = paste(NAMES[i], "(", AUCs[i],")")
# print(paste(NAMES[i], "AUC-ROC=", auc@y.values))
}
abline(a=0, b=1, lty=2, lwd=3, col="black")
pred
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
perf = performance(pred, 'tpr', 'fpr')
if (i==1) { plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves") }
else { plot(perf, add = TRUE, colorize = FALSE, lwd=3, col=COLORS[i]) }
}
plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves")
library("ROCR")
library("hash")
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
perf = performance(pred, 'tpr', 'fpr')
if (i==1) { plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves") }
else { plot(perf, add = TRUE, colorize = FALSE, lwd=3, col=COLORS[i]) }
}
AUCs = rep(0, length(RESULTS_FILES))
LNAMES = rep(0, length(RESULTS_FILES))
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
auc = performance(pred, measure='auc')
AUCs[i] = sprintf("%.3f", auc@y.values)
LNAMES[i] = paste(NAMES[i], "(", AUCs[i],")")
# print(paste(NAMES[i], "AUC-ROC=", auc@y.values))
}
abline(a=0, b=1, lty=2, lwd=3, col="black")
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
perf = performance(pred, 'tpr', 'fpr')
if (i==1) { plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves") }
else { plot(perf, add = TRUE, colorize = FALSE, lwd=3, col=COLORS[i]) }
}
AUCs = rep(0, length(RESULTS_FILES))
LNAMES = rep(0, length(RESULTS_FILES))
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
auc = performance(pred, measure='auc')
AUCs[i] = sprintf("%.3f", auc@y.values)
LNAMES[i] = paste(NAMES[i], "(", AUCs[i],")")
# print(paste(NAMES[i], "AUC-ROC=", auc@y.values))
}
legend(0.62, 0.28, legend=LNAMES,
col=COLORS, lty=1, cex=0.8)
COLORS <- rainbow(3*length(RESULTS_FILES))
COLORS <- COLORS[seq(3, length(COLORS), 3)]
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
perf = performance(pred, 'tpr', 'fpr')
if (i==1) { plot(perf, add = FALSE, colorize = FALSE, lwd=3, col=COLORS[i], main="ROC Curves") }
else { plot(perf, add = TRUE, colorize = FALSE, lwd=3, col=COLORS[i]) }
}
AUCs = rep(0, length(RESULTS_FILES))
LNAMES = rep(0, length(RESULTS_FILES))
for (i in 1:length(RESULTS_FILES)) {
pred = read_scores(RESULTS_FILES[i], ACTIVITIES_FILE, valid_molnames)
auc = performance(pred, measure='auc')
AUCs[i] = sprintf("%.3f", auc@y.values)
LNAMES[i] = paste(NAMES[i], "(", AUCs[i],")")
# print(paste(NAMES[i], "AUC-ROC=", auc@y.values))
}
abline(a=0, b=1, lty=2, lwd=3, col="black")
# Add legend
legend(0.62, 0.28, legend=LNAMES,
col=COLORS, lty=1, cex=0.8)
knitr::read_chunk("function_definitions.r")
